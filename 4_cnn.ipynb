{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H8qiR1fW4V66"
   },
   "source": [
    "# Семинар 4: ` Keras` и сверточные нейронные сети\n",
    "\n",
    "На семинаре мы при помощи библиотеки `keras` обучим глубокую сверточную нейронную сеть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2TlKzA9s7NxX"
   },
   "source": [
    "Библиотека `keras` — надстройка над фреймворками [Tensorflow](https://www.tensorflow.org/), [Theano](http://deeplearning.net/software/theano/), [CNTK](https://docs.microsoft.com/en-us/cognitive-toolkit/). Можно использовать в качестве бэкенда любой из этих фреймворков, и код будет исполняться независмо от выбранного бэкенда. По умолчанию `keras` работает с `tensorflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eeuAxwCYEstl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.backend.backend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WzkOOpbgFSM_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MatMul:0\", shape=(4, 4), dtype=float32) \n",
      "\n",
      "c: \n",
      " [[3.338108   2.4369338  3.3162317  3.0676663 ]\n",
      " [1.2508358  1.4171395  1.4698844  1.8300776 ]\n",
      " [0.37694338 0.37492004 0.67462504 0.37973586]\n",
      " [1.8413678  2.4478116  2.1607587  2.2805357 ]]\n",
      "d: \n",
      " [2.5633025 2.6991744 3.0342622 3.4339776]\n",
      "b: \n",
      " [[0.6868795  0.10215402 0.9560753  0.2799462  0.53824747 3.338108\n",
      "  2.4369338  3.3162317  3.0676663 ]\n",
      " [0.7791878  0.3839116  0.37285638 0.68732035 0.47589815 1.2508358\n",
      "  1.4171395  1.4698844  1.8300776 ]\n",
      " [0.53053725 0.20323586 0.86687803 0.7380997  0.6955112  0.37694338\n",
      "  0.37492004 0.67462504 0.37973586]\n",
      " [0.72693145 0.9145076  0.7043344  0.6261914  0.4620129  1.8413678\n",
      "  2.4478116  2.1607587  2.2805357 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "# соответствует tf.placeholder() или th.tensor.matrix(), th.tensor.tensor3(), и т. д. в зависимости от бэкенда\n",
    "inputs = K.placeholder(shape=(2, 4, 5))\n",
    "inputs = K.placeholder(shape=(None, 4, 5))\n",
    "inputs = K.placeholder(ndim=3)\n",
    "\n",
    "# делать операции над тензорами можно как мы привыкли с tensorflow\n",
    "b = K.random_uniform_variable(shape=(4, 5), low=0, high=1)\n",
    "c = K.random_normal_variable(shape=(4, 5), mean=0, scale=1)\n",
    "\n",
    "a = b + c * K.abs(b)\n",
    "c = K.dot(a, K.transpose(b))\n",
    "d = K.sum(b, axis=1)\n",
    "b = K.concatenate([b, c], axis=-1)\n",
    "\n",
    "# в результате операций над тензорами получили неинициализированный тензор, как и для tensorflow\n",
    "print(c, \"\\n\")\n",
    "\n",
    "# а теперь посчитаем, чему будут равны тензоры для конкретных входных данных\n",
    "print(\"c: \\n\", K.eval(c))\n",
    "print(\"d: \\n\", K.eval(d))\n",
    "print(\"b: \\n\", K.eval(b))\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t651plf_SDfB"
   },
   "source": [
    "# Keras Sequential API\n",
    "Основная структура данных в `Keras` —  это  `model`, способ организовать слои в нейронной сети. Простейший способ создать модель — использовать `Sequential()`. Такая модель представляет из себя стек слоев, идущих последовательно друг за другом, именно такой моделью мы и будем сегодня пользоваться для обучения сверточной нейронной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Be6HwRHbN9b"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder_3:0\", shape=(), dtype=float32) is not an element of this graph.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1091\u001b[0m             subfeed_t = self.graph.as_graph_element(\n\u001b[0;32m-> 1092\u001b[0;31m                 subfeed, allow_tensor=True, allow_operation=False)\n\u001b[0m\u001b[1;32m   1093\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3556\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor Tensor(\"Placeholder_3:0\", shape=(), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1d61f5f3c102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# обучаем модель, указываем количество шагов градиентного спуска, размер батча\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# Setup work for each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1117\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'metrics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0mtraining_distributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m     \"\"\"\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m       \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mset_value\u001b[0;34m(x, value)\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2846\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2847\u001b[0;31m       \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1093\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             raise TypeError(\n\u001b[0;32m-> 1095\u001b[0;31m                 'Cannot interpret feed_dict key as Tensor: ' + e.args[0])\n\u001b[0m\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret feed_dict key as Tensor: Tensor Tensor(\"Placeholder_3:0\", shape=(), dtype=float32) is not an element of this graph."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# для первого слоя  в последовательности нужно указать размерности входных данных\n",
    "# для других слоев делать это уже не нужно\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# компилируем модель, определяем функцию потерь, метрику качества, метод оптимизации\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(10, size=(1000, 1))\n",
    "\n",
    "one_hot_labels = to_categorical(labels, num_classes=10)\n",
    "\n",
    "# обучаем модель, указываем количество шагов градиентного спуска, размер батча\n",
    "model.fit(data, one_hot_labels, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_dIPr0B3dVxs"
   },
   "source": [
    "# Keras Callbacks\n",
    "Callbacks — это набор функций, которые можно передать в процедуру обучения модели. Можно использовать колбэки, чтобы следить за метриками во время обучения, что может быть полезно для дебага, сохранять модель и так далее. Список колбэков передается в `.fit()`, релевантные колбэки вызываются на каждой итерации обучения.\n",
    "\n",
    "В `keras` реализовано [много полезных колбэков](https://keras.io/callbacks/), так же есть возможность писать кастомные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8Bsuv4ZhuDm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'EarlyStopping' object has no attribute 'on_train_batch_begin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-86d0764680a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m           callbacks=[keras.callbacks.EarlyStopping(monitor='loss'), # добавим еще EarlyStopping, реализованный в keras\n\u001b[0;32m---> 29\u001b[0;31m                      history]\n\u001b[0m\u001b[1;32m     30\u001b[0m          )\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# Callbacks batch_begin.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mt_before_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m       \u001b[0mbatch_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m       \u001b[0mbatch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EarlyStopping' object has no attribute 'on_train_batch_begin'"
     ]
    }
   ],
   "source": [
    "# определим кастомный колбэк, который выводит функции потерь для каждого батча на каждой итерации\n",
    "class LossHistory(keras.callbacks.Callback):        \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        # в self.losses будем хранить искомый список функций потерь для батчей, надо его инициализировать\n",
    "        # еще можно вывести номер итерации\n",
    "        ### YOUR CODE HERE\n",
    "        self.losses = []\n",
    "        print(\"Epoch:\", epoch)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # выполнили один шаг градиентного спуска, самое время вывести вычисленные функции потерь\n",
    "        ### YOUR CODE HERE \n",
    "        print(\"Batch losses:\", self.losses)\n",
    "        print(\"Loss:\", logs.get('loss'))\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        # закончили обрабатывать батч, надо сохранить лосс, он лежит в logs.get('loss')\n",
    "        ### YOUR CODE HERE \n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "\n",
    "history = LossHistory()\n",
    "model.fit(data,\n",
    "          one_hot_labels,\n",
    "          epochs=10,\n",
    "          batch_size=200,\n",
    "          verbose=0,\n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor='loss'), # добавим еще EarlyStopping, реализованный в keras\n",
    "                     history]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oq_W8bZckif9"
   },
   "source": [
    "# Сверточная нейронная сеть для CIFAR-10\n",
    "\n",
    "Датасет CIFAR-10 содержит цветные картинки 32x32, каждая из которых принадлежит одному из 10 классов: __airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck__\n",
    "\n",
    "В задании нужно будет:\n",
    "* Определить архитектуру CNN\n",
    "* Обучить модель\n",
    "* Визуализировать обученные фильтры\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-nuNBH9m3ls"
   },
   "source": [
    "**ОБРАТИТЕ ВНИМАНИЕ:** обучение CNN на CPU для этого задания может занимать достаточно много времени, 0.5-1.5 часа, поэтому будем обучать модель на GPU\n",
    "\n",
    "**Runtime -> Change runtime type** и выберите **GPU** в Google Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_u4Rwpd8fBIv"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DZtgoH5VfBI0"
   },
   "outputs": [],
   "source": [
    "# чистим сессию, чтобы не получить out-of-memory\n",
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    K.clear_session()\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4X4OxWejnj46"
   },
   "source": [
    "# Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Vs5Mo1mCfBI3"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "w71tZ9tEfBI6"
   },
   "outputs": [],
   "source": [
    "print(\"Train samples:\", x_train.shape, y_train.shape)\n",
    "print(\"Test samples:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "ka43TeITfBI9"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "cifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
    "                   \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1SIWT_T6fBJA"
   },
   "outputs": [],
   "source": [
    "# посмотрим на случайные картинки из датасета\n",
    "cols = 8\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols - 1, 2.5 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_train))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid(False)\n",
    "        ax.axis('off')\n",
    "        ax.imshow(x_train[random_index, :])\n",
    "        ax.set_title(cifar10_classes[y_train[random_index, 0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PvM_vzk6ntxw"
   },
   "source": [
    "# Нормализация данных\n",
    "Как мы знаем, нейронные сети любят, когда входные данные нормализованы, нормализуем их: $$x_{norm} = \\frac{x}{255} - 0.5$$\n",
    "\n",
    "Так же нужно преобразовать классы в one-hot encoded векторы с помощью __keras.utils.to_categorical__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FSvuvnTyfBJC"
   },
   "outputs": [],
   "source": [
    "# нормализуем входные данные\n",
    "x_train2 = ### YOUR CODE HERE\n",
    "x_test2 = ### YOUR CODE HERE\n",
    "\n",
    "# преобразуем метки классов в one-hot encoded векторы, должно получиться(?, NUM_CLASSES)\n",
    "y_train2 = ### YOUR CODE HERE\n",
    "y_test2 = ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cLK8CZPnopbV"
   },
   "source": [
    "# Архитектура CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4__6vztrfBJF"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C2zEKlLkpNCH"
   },
   "source": [
    "Сверточные нейронные сети строятся из нескольких типов слоев:\n",
    "- [Conv2D](https://keras.io/layers/convolutional/#conv2d) - свертка:\n",
    "    - **filters**: количество выходных каналов; \n",
    "    - **kernel_size**: ширина и высота окна для свертки, tuple/list из двух целых чисел;\n",
    "    - **padding**: padding=\"same\" добавляет столько нулей, чтобы выходной канал имел такие же размеры, как и вход, при padding='valid' свертка выполняется только там, где ядро свертки полностью пересекается с входным каналом;\n",
    "    - **activation**: \"relu\", \"tanh\", и т.д.\n",
    "    - **input_shape**: размерности входных данных.\n",
    "- [MaxPooling2D](https://keras.io/layers/pooling/#maxpooling2d) - выполняет 2D max pooling.\n",
    "- [Flatten](https://keras.io/layers/core/#flatten) - не затрагивает размерность,  соответствующую размеру батча.\n",
    "- [Dense](https://keras.io/layers/core/#dense) - полносвязный слой.\n",
    "- [Activation](https://keras.io/layers/core/#activation) - применяет функцию активации.\n",
    "- [LeakyReLU](https://keras.io/layers/advanced-activations/#leakyrelu) - применяет функцию активации leaky relu.\n",
    "- [Dropout](https://keras.io/layers/core/#dropout) - применяет dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obhlpRpBsL1t"
   },
   "source": [
    "Размерность входных данных для модели __(None, 32, 32, 3)__ , размерность выходных __(None, 10)__ . __None__ соответствует размерности размера батча.\n",
    "\n",
    "Шаблон модели:\n",
    "\n",
    "```python\n",
    "model = Sequential() \n",
    "model.add(Conv2D(..., input_shape=(32, 32, 3)))  # не забываем определить размерность входа для первого слоя\n",
    "\n",
    "...  # сверточные слои, пулинг, дропаут\n",
    "\n",
    "model.add(Dense(NUM_CLASSES))  \n",
    "model.add(Activation(\"softmax\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_16Uh2L-fBJH"
   },
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    \"\"\"\n",
    "    Define your model architecture here.\n",
    "    Returns `Sequential` model.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    model = Sequential()\n",
    "      \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "sAny7mzafBJL"
   },
   "outputs": [],
   "source": [
    "s = reset_tf_session()\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ao3gB8izLUDI"
   },
   "source": [
    "# Обучение модели\n",
    "\n",
    "На GPU 10-20 секунд на эпоху.\n",
    "Добавим в обучение уменьшение learning rate с номером эпохи при помощи callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "h78soVObfBJQ"
   },
   "outputs": [],
   "source": [
    "INIT_LR = 5e-3  # стартовый learning rate\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "s = reset_tf_session()\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "# определите функцию потреть, метод оптимизации и метрику качества\n",
    "### YOUR CODE HERE\n",
    "\n",
    "# формула, по которой будет меняться learning rate в зависимости от эпохи, передадим ее в LearningRateScheduler callback\n",
    "def lr_scheduler(epoch):\n",
    "    return INIT_LR * 0.9 ** epoch\n",
    "\n",
    "# будем выводить актуальный learning rate в начале каждой итерации (on_epoch_begin)\n",
    "# для этого нужно написать кастомный callback\n",
    "class LrHistory(keras.callbacks.Callback):\n",
    "    ### YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "yIklukijfBJS"
   },
   "outputs": [],
   "source": [
    "# обучаем модель\n",
    "model.fit(\n",
    "    x_train2, y_train2,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[keras.callbacks.LearningRateScheduler(lr_scheduler), \n",
    "               LrHistory(),],\n",
    "    validation_data=(x_test2, y_test2),\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    initial_epoch=0    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TK_eOCmpfBJW"
   },
   "outputs": [],
   "source": [
    "# сохраняем веса модели\n",
    "model.save_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bKFb-mgxfBJa"
   },
   "outputs": [],
   "source": [
    "# загружаем веса (можно не вызывать model.fit, если модель была однажды обучена и веса сохранены)\n",
    "model.load_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BzGTGsmANKi1"
   },
   "source": [
    "# Применение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2H6PmfL_fBJd"
   },
   "outputs": [],
   "source": [
    "# вычисляем прогноз для тестовых данных\n",
    "y_pred_test = model.predict_proba(x_test2)\n",
    "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
    "y_pred_test_max_probas = np.max(y_pred_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "REz2iK6LfBJh"
   },
   "outputs": [],
   "source": [
    "# матрица ошибок и точность\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.title('Confusion matrix', fontsize=16)\n",
    "plt.imshow(confusion_matrix(y_test, y_pred_test_classes))\n",
    "plt.xticks(np.arange(10), cifar10_classes, rotation=45, fontsize=12)\n",
    "plt.yticks(np.arange(10), cifar10_classes, fontsize=12)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred_test_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-d7wvTVUfBJj"
   },
   "outputs": [],
   "source": [
    "# посмотрим на предсказания\n",
    "cols = 8\n",
    "rows = 2\n",
    "fig = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1))\n",
    "for i in range(cols):\n",
    "    for j in range(rows):\n",
    "        random_index = np.random.randint(0, len(y_test))\n",
    "        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "        ax.grid(False)\n",
    "        ax.axis(\"off\")\n",
    "        ax.imshow(x_test[random_index, :])\n",
    "        pred_label = cifar10_classes[y_pred_test_classes[random_index]]\n",
    "        pred_proba = y_pred_test_max_probas[random_index]\n",
    "        true_label = cifar10_classes[y_test[random_index, 0]]\n",
    "        ax.set_title(\"pred: {}\\nscore: {:.3}\\ntrue: {}\".format(\n",
    "               pred_label, pred_proba, true_label\n",
    "        ))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BtpSzXimNrm8"
   },
   "source": [
    "# Визуализация фильтров\n",
    "\n",
    "Мы хотим найти входные изображения, максимизирующие активации для заданного слоя нейронной сети.\n",
    "\n",
    "Задача очень похожа на задачу обучения весов для нейронной сети: при обучении весов нам нужно найти веса, минимизирующие функцию потерь, для данного входного изображения. Решаем эту задачу градиентным спуском, ищем градиент функции потерь по весам.\n",
    "\n",
    "Теперь мы хотим найти входное изображение, максимизирующее среднее значение активации на заданном слое\n",
    "$$Loss(layer) = Mean(layer) = \\frac{1}{|layer|}\\sum_{x \\in layer}x \\rightarrow \\max    $$\n",
    "\n",
    "Задачи максимизации решаются аналогично задачам минимизации с помощью градиентного подъема\n",
    "\n",
    "$$image_{t+1} = Image_t + \\gamma\\frac{\\partial  Loss}{\\partial   Image_t}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "pFqITQfCfBJp"
   },
   "outputs": [],
   "source": [
    "s = reset_tf_session()\n",
    "K.set_learning_phase(0)\n",
    "model = make_model()\n",
    "model.load_weights(\"weights.h5\")  # веса сохранены после обучения model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "V4oCGZabfBJr"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "hyMAwN0MfBJu"
   },
   "outputs": [],
   "source": [
    "def find_maximum_stimuli(layer_name, is_conv, filter_index, model, iterations=20, step=1., verbose=True):\n",
    "    \n",
    "    def image_values_to_rgb(x):\n",
    "        # нормализуем x: центрируем в 0 (np.mean(x_train2)), убедиться, что std=0.25 (np.std(x_train2))\n",
    "        # теперь х такой же как нормализованный вход нейронной сети\n",
    "        x = ### YOUR CODE HERE        \n",
    "\n",
    "        # преобразуем нормализованный вход обратно к RGB: x = (x_norm + 0.5) * 255\n",
    "        x = ### YOUR CODE HERE\n",
    "    \n",
    "        x = np.clip(x, 0, 255).astype('uint8')\n",
    "        return x\n",
    "\n",
    "    # placeholder для входного изображения\n",
    "    input_img = model.input\n",
    "    img_width, img_height = input_img.shape.as_list()[1:3]\n",
    "    \n",
    "    # находим выходы заданного слоя\n",
    "    layer_output = list(filter(lambda x: x.name == layer_name, model.layers))[0].output\n",
    "    \n",
    "    # определите функцию потерь, обратите внимание, что мы можем считать ее \n",
    "    # как для сверточного слоя, так и для полносвязного\n",
    "\n",
    "    loss = ### YOUR CODE HERE\n",
    "\n",
    "    # посчитайте градиент функции потерь по входному изображению с помощью  K.gradients\n",
    "\n",
    "    grads = ### YOUR CODE HERE\n",
    "\n",
    "    # normalization trick\n",
    "    grads = grads / (K.sqrt(K.sum(K.square(grads))) + 1e-10)\n",
    "\n",
    "    # считаем градиенты\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # инициализируем входное ихображение: серое изображение со случайным шумом\n",
    "    input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * (0.1 if is_conv else 0.001)\n",
    "\n",
    "    # градиентный подъем\n",
    "    for i in range(iterations):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "        if verbose:\n",
    "            print('Current loss value:', loss_value)\n",
    "\n",
    "    # преобразуем изображение в RGB формат\n",
    "    img = image_values_to_rgb(input_img_data[0])\n",
    "    \n",
    "    return img, loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1KwH686LfBJx"
   },
   "outputs": [],
   "source": [
    "# sample maximum stimuli\n",
    "def plot_filters_stimuli(layer_name, is_conv, model, iterations=20, step=1., verbose=False):\n",
    "    cols = 8\n",
    "    rows = 2\n",
    "    filter_index = 0\n",
    "    max_filter_index = list(filter(lambda x: x.name == layer_name, model.layers))[0].output.shape.as_list()[-1] - 1\n",
    "    fig = plt.figure(figsize=(2 * cols - 1, 3 * rows - 1))\n",
    "    for i in range(cols):\n",
    "        for j in range(rows):\n",
    "            if filter_index <= max_filter_index:\n",
    "                ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n",
    "                ax.grid(False)\n",
    "                ax.axis('off')\n",
    "                loss = -1e20\n",
    "                while loss < 0 and filter_index <= max_filter_index:\n",
    "                    stimuli, loss = find_maximum_stimuli(layer_name, is_conv, filter_index, model,\n",
    "                                                         iterations, step, verbose=verbose)\n",
    "                    filter_index += 1\n",
    "                if loss > 0:\n",
    "                    ax.imshow(stimuli)\n",
    "                    ax.set_title(\"Filter #{}\".format(filter_index))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "naj2ZdlNfBJ1"
   },
   "outputs": [],
   "source": [
    "# maximum stimuli for convolutional neurons\n",
    "conv_activation_layers = []\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, LeakyReLU):\n",
    "        prev_layer = layer._inbound_nodes[0].inbound_layers[0]\n",
    "        if isinstance(prev_layer, Conv2D):\n",
    "            conv_activation_layers.append(layer)\n",
    "\n",
    "for layer in conv_activation_layers:\n",
    "    print(layer.name)\n",
    "    plot_filters_stimuli(layer_name=layer.name, is_conv=True, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "MnHJEEpxfBJ5"
   },
   "outputs": [],
   "source": [
    "# maximum stimuli for last dense layer\n",
    "last_dense_layer = list(filter(lambda x: isinstance(x, Dense), model.layers))[-1]\n",
    "plot_filters_stimuli(layer_name=last_dense_layer.name, is_conv=False, \n",
    "                     iterations=200, step=0.1, model=model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "4_cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
